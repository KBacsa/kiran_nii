{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# basic\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import itertools\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import random_split\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# plot\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# machine learning\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# custom\n",
    "import video_loader\n",
    "import custom_models as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# manual setting of clusters, as an alternative to graph inference\n",
    "manual_tree = np.zeros((98,5), dtype=int)\n",
    "list_ = [17, 13, 15, 16, 11, 12, 10, 14,\n",
    "          3, 4, 9, 8, 6, 5, 7, 0, 1, 2,\n",
    "          35, 36, 37, 38, 31, 32, 33, 34,\n",
    "          30, 28, 29, 19, 20, 21, 25, 26, 27, 24, 22, 23,\n",
    "          48, 46, 47, 43, 44, 45, 39, 40, 41, 18, 42]\n",
    "\n",
    "second_list = []\n",
    "\n",
    "for i in list_:\n",
    "    second_list.append(i*2)\n",
    "    second_list.append(i*2 + 1)\n",
    "    \n",
    "manual_tree[:,0] = second_list\n",
    "\n",
    "manual_tree[:20,1] = 0\n",
    "manual_tree[20:38,1] = 1\n",
    "manual_tree[38:62,1] = 2\n",
    "manual_tree[62:78,1] = 3\n",
    "manual_tree[78:,1] = 4\n",
    "\n",
    "manual_tree[:38,2] = 0\n",
    "manual_tree[38:62,2] = 1\n",
    "manual_tree[62:,2] = 2\n",
    "\n",
    "manual_tree[:38,3] = 0\n",
    "manual_tree[38:,3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "manual_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See finetung.ipynb for remarks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CK+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "classes =  {0:'anger', 1:'contempt', 2:'disgust', 3:'fear', 4:'happy', 5:'sadness', 6:'surprise'}\n",
    "N_frames = 3\n",
    "N_classes = len(classes)\n",
    "N_landmarks = 68\n",
    "\n",
    "# preprocessing\n",
    "data_dir = os.path.join('/home','nii','Documents','CK+')\n",
    "\n",
    "data_transforms = transforms.Compose(\n",
    "    [transforms.Resize((64,64))])\n",
    "\n",
    "K = 10\n",
    "k_folders = ['set_' + str(idx) for idx in range(K)]\n",
    "\n",
    "    \n",
    "training_datasets = {x: video_loader.VideoFolder(root=data_dir, image_folder='cohn-kanade-images-crop', \n",
    "                                 label_folder='Emotion', landmark_folder='Landmarks_crop',\n",
    "                                 fold=x, phase='train', classes=classes, n_frames=N_frames, transform=data_transforms,\n",
    "                                                 n_landmarks=N_landmarks,\n",
    "                                 indexing=1)\n",
    "                    for x in k_folders}\n",
    "\n",
    "validation_datasets = {x: video_loader.VideoFolder(root=data_dir, image_folder='cohn-kanade-images-crop', \n",
    "                                 label_folder='Emotion', landmark_folder='Landmarks_crop',\n",
    "                                 fold=x, phase='valid', classes=classes, n_frames=N_frames, transform=data_transforms,\n",
    "                                                   n_landmarks=N_landmarks,\n",
    "                                 indexing=1)\n",
    "                    for x in k_folders}\n",
    "\n",
    "fold = 0\n",
    "\n",
    "training_folds = [x for x in range(K) if x != fold]\n",
    "validation_fold = random.choice(training_folds)\n",
    "training_folds = [x for x in training_folds if x is not validation_fold]\n",
    "\n",
    "cross_datasets = {}\n",
    "cross_datasets['train'] = torch.utils.data.ConcatDataset([training_datasets[k_folders[k]] \n",
    "                                                          for k in training_folds])\n",
    "cross_datasets['val'] = validation_datasets[k_folders[validation_fold]]\n",
    "\n",
    "cross_datasets['test'] = validation_datasets[k_folders[fold]]\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(cross_datasets[x], batch_size=32,\n",
    "                                              num_workers=8, shuffle=True)\n",
    "              for x in ['train', 'val', 'test']}\n",
    "\n",
    "dataset_sizes = {x: len(cross_datasets[x]) for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oulu-CASIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "classes =  {0:'anger', 1:'disgust', 2:'fear', 3:'happy', 4:'sadness', 5:'surprise'}\n",
    "data_dir = os.path.join('/home','nii','Documents', 'OriginalImg', 'VL')\n",
    "N_frames = 3\n",
    "N_classes = len(classes)\n",
    "N_landmarks = 68\n",
    "\n",
    "data_transforms = transforms.Compose(\n",
    "    [transforms.Resize((64,64))])\n",
    "\n",
    "K = 10\n",
    "k_folders = ['set_' + str(idx) for idx in range(K)]\n",
    "    \n",
    "training_datasets = {x: video_loader.VideoFolder(root=data_dir, image_folder='Strong-crop', \n",
    "                                 label_folder='Strong-emotion', landmark_folder='Landmarks_crop',\n",
    "                                 fold=x, phase='train', classes=classes, img_type='jpeg', n_landmarks=N_landmarks,\n",
    "                                    n_frames=N_frames, transform=data_transforms)\n",
    "                    for x in k_folders}\n",
    "\n",
    "validation_datasets = {x: video_loader.VideoFolder(root=data_dir, image_folder='Strong-crop', \n",
    "                                 label_folder='Strong-emotion', landmark_folder='Landmarks_crop',\n",
    "                                 fold=x, phase='valid', classes=classes, img_type='jpeg', n_landmarks=N_landmarks,\n",
    "                                      n_frames=N_frames, transform=data_transforms)\n",
    "                    for x in k_folders}\n",
    "\n",
    "\n",
    "fold = 6\n",
    "\n",
    "training_folds = [x for x in range(K) if x != fold]\n",
    "validation_fold = random.choice(training_folds)\n",
    "training_folds = [x for x in training_folds if x is not validation_fold]\n",
    "\n",
    "cross_datasets = {}\n",
    "cross_datasets['train'] = torch.utils.data.ConcatDataset([training_datasets[k_folders[k]] \n",
    "                                                          for k in training_folds])\n",
    "cross_datasets['val'] = validation_datasets[k_folders[validation_fold]]\n",
    "\n",
    "cross_datasets['test'] = validation_datasets[k_folders[fold]]\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(cross_datasets[x], batch_size=32,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val', 'test']}\n",
    "\n",
    "dataset_sizes = {x: len(cross_datasets[x]) for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AFEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes =  {0:'neutral', 1:'angry', 2:'disgust', 3:'fear', 4:'happy', 5:'sad', 6:'surprise'}\n",
    "N_frames = 3\n",
    "N_landmarks = 49\n",
    "N_classes = len(classes)\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "# preprocessing\n",
    "data_dir = os.path.join('/home','nii','Documents','EmotiW_2018','Train_AFEW')\n",
    "data_dir_val = os.path.join('/home','nii','Documents','EmotiW_2018','Val_AFEW')\n",
    "\n",
    "data_transforms = transforms.Compose(\n",
    "    [transforms.Resize((64,64))])\n",
    "\n",
    "K = 10\n",
    "k_folders = ['set_' + str(idx) for idx in range(K)]   \n",
    "\n",
    "    \n",
    "training_datasets = {x: video_loader.VideoFolder(root=data_dir, image_folder='cropped_images', \n",
    "                                 label_folder='emotion', landmark_folder='landmarks',\n",
    "                                 fold=x, phase='train', img_type='jpg',\n",
    "                                 classes=classes, n_frames=N_frames, n_landmarks=N_landmarks,\n",
    "                                 transform=data_transforms, indexing=0,\n",
    "                                   are_subjects=False)\n",
    "                    for x in k_folders}\n",
    "\n",
    "\n",
    "validation_datasets = {x: video_loader.VideoFolder(root=data_dir, image_folder='cropped_images', \n",
    "                                 label_folder='emotion', landmark_folder='landmarks',\n",
    "                                 fold=x, phase='valid', img_type='jpg',\n",
    "                                 classes=classes, n_frames=N_frames,  n_landmarks=N_landmarks,\n",
    "                                 transform=data_transforms, indexing=0,\n",
    "                                     are_subjects=False)\n",
    "                    for x in k_folders}\n",
    "\n",
    "testing_datasets = {x: video_loader.VideoFolder(root=data_dir_val, image_folder='cropped_images', \n",
    "                                 label_folder='emotion', landmark_folder='landmarks',\n",
    "                                 fold=x, phase='test', img_type='jpg',\n",
    "                                 classes=classes, n_frames=N_frames,  n_landmarks=N_landmarks,\n",
    "                                 transform=data_transforms, indexing=0,\n",
    "                                     are_subjects=False)\n",
    "                    for x in k_folders}\n",
    "\n",
    "fold = 6\n",
    "\n",
    "training_folds = [x for x in range(K) if x != fold]\n",
    "validation_fold = fold\n",
    "\n",
    "cross_datasets = {}\n",
    "cross_datasets['train'] = torch.utils.data.ConcatDataset([training_datasets[k_folders[k]] \n",
    "                                                          for k in training_folds])\n",
    "cross_datasets['val'] = validation_datasets[k_folders[validation_fold]]\n",
    "\n",
    "cross_datasets['test'] = torch.utils.data.ConcatDataset([testing_datasets[k_folders[k]] \n",
    "                                                          for k in range(K)])\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(cross_datasets[x], batch_size=32, shuffle=True,\n",
    "                                              num_workers=4)\n",
    "              for x in ['train', 'val', 'test']}\n",
    "\n",
    "dataset_sizes = {x: len(cross_datasets[x]) for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "videos, classes, ld = next(iter(dataloaders['val']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=25, min_epoch=100, k=5, alpha=3):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_loss = 1e6\n",
    "    \n",
    "    epoch = 0\n",
    "    stop_criterion = True\n",
    "    \n",
    "    train_accuracy = []\n",
    "    val_accuracy = []\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    \n",
    "    #for epoch in range(num_epochs):\n",
    "    while stop_criterion:\n",
    "        #print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('Epoch {}'.format(epoch))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                # get the inputs\n",
    "                _, labels, landmarks = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(landmarks.float().cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(landmarks.float()), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0] * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_accuracy.append(epoch_acc)\n",
    "                train_loss.append(epoch_loss)\n",
    "            else:\n",
    "                val_accuracy.append(epoch_acc)\n",
    "                val_loss.append(epoch_loss)\n",
    "                GL = 100 * (epoch_loss/best_loss - 1)\n",
    "                Pk = 1000 * (sum(train_loss[-k:]) / (k*min(train_loss[-k:])) - 1)\n",
    "                PQ = GL / Pk\n",
    "                \n",
    "                print('PQ = ' + str(PQ))\n",
    "                \n",
    "                if (PQ > alpha and epoch >= min_epoch) or epoch == num_epochs:\n",
    "                    stop_criterion = False\n",
    "                    \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc >= best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        epoch += 1\n",
    "        \n",
    "        print()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_acc, train_accuracy, train_loss, val_accuracy, val_loss\n",
    "\n",
    "\n",
    "def test_model(model, criterion):\n",
    "    \n",
    "    model.train(False)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    \n",
    "    truth = []\n",
    "    prediction = []\n",
    "\n",
    "    # Iterate over data.\n",
    "    for data in dataloaders['test']:\n",
    "        # get the inputs\n",
    "        _, labels, landmarks = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        if use_gpu:\n",
    "            inputs = Variable(landmarks.float().cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(landmarks.float()), Variable(labels)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # statistics\n",
    "        running_loss += loss.data[0] * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        truth.extend(labels.cpu().data.numpy().tolist())\n",
    "        prediction.extend(preds.cpu().numpy().tolist())\n",
    "\n",
    "    total_loss = running_loss / dataset_sizes['test']\n",
    "    total_acc = running_corrects / dataset_sizes['test']\n",
    "\n",
    "    print('{} Loss: {:.4f} Acc: {:.4f}'.format('test', total_loss, total_acc))\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(truth, prediction, labels=list(range(N_classes)))\n",
    "\n",
    "    return total_loss, total_acc, cnf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally this should be in its own file, for debugging purposes it was kept in the main script. The make_layers and forward functions still have some issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BiRNN Model (Many-to-One)\n",
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(BiRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, \n",
    "                            batch_first=True, bidirectional=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Set initial states\n",
    "        if x.is_cuda:\n",
    "            h0 = Variable(torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).cuda()) # 2 for bidirection \n",
    "            \n",
    "        else:\n",
    "            h0 = Variable(torch.zeros(self.num_layers*2, x.size(0), self.hidden_size)) # 2 for bidirection \n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, \n",
    "                            batch_first=True, bidirectional=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Set initial states\n",
    "        if x.is_cuda:\n",
    "            h0 = Variable(torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).cuda()) # 2 for bidirection \n",
    "            c0 = Variable(torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).cuda())\n",
    "            \n",
    "        else:\n",
    "            h0 = Variable(torch.zeros(self.num_layers*2, x.size(0), self.hidden_size)) # 2 for bidirection \n",
    "            c0 = Variable(torch.zeros(self.num_layers*2, x.size(0), self.hidden_size))\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Decode hidden state of last time step\n",
    "        #out = out[:, -1, :]\n",
    "        \n",
    "        return out\n",
    "    \n",
    "\n",
    "def make_layers(cfg):\n",
    "    layers = []\n",
    "    factor = 1\n",
    "    for v in cfg:\n",
    "        # extract layer configuration\n",
    "        mask, hidden_size, n_layers, double, memory = v\n",
    "        if memory:\n",
    "            # memory layer\n",
    "            #factor *= 2 # temporary correction --> multiply by the number of previous layers\n",
    "            layers += [BiLSTM(len(mask)*factor, hidden_size, n_layers)]\n",
    "        else:\n",
    "            layers += [nn.ModuleList([BiRNN(len(mask[i])*factor, hidden_size, n_layers)\n",
    "                                for i in range(len(mask))])]\n",
    "            if double:\n",
    "                layers += [nn.ModuleList([BiRNN(hidden_size*2, hidden_size, n_layers)\n",
    "                               for i in range(len(mask))])]\n",
    "        factor = 2 * hidden_size\n",
    "        \n",
    "    return nn.ModuleList(layers)\n",
    "\n",
    "\n",
    "class Flexible(nn.Module):\n",
    "    def __init__(self, cfg, n_landmarks, n_classes, use_mask=True):\n",
    "        super(Flexible, self).__init__()\n",
    "        \n",
    "        self.n_landmarks = n_landmarks\n",
    "        self.n_classes = n_classes\n",
    "        self.cfg = cfg\n",
    "        self.use_mask = use_mask\n",
    "        \n",
    "        # feature extraction\n",
    "        self.features = make_layers(self.cfg)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(480, 8192),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(8192, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(4096, self.n_classes),\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        #\"\"\"\n",
    "        if self.use_mask: \n",
    "            x = x.view(batch_size, -1, 2*68)\n",
    "            mask = np.ones((2*68, 1),  dtype=bool)\n",
    "            mask[:34] = False\n",
    "            mask[120:122] = False\n",
    "            mask[128:130] = False\n",
    "            x = x[:,:,np.where(mask)[0]]\n",
    "            \n",
    "        else:\n",
    "            x = x.view(batch_size, -1, 2*49)\n",
    "        #\"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        x = x.view(batch_size, -1, 2*68)\n",
    "        mask = np.ones((2*68, 1),  dtype=bool)\n",
    "        mask[:34] = False\n",
    "        mask[120:122] = False\n",
    "        mask[128:130] = False\n",
    "        x = x[:,:,np.where(mask)[0]]\n",
    "        \"\"\"\n",
    "        \n",
    "        num_layer = 0\n",
    "        for v in self.cfg:\n",
    "            # extract layer configuration\n",
    "            \n",
    "            mask, hidden_size, n_layers, double, memory = v\n",
    "            \n",
    "            # LSTM layer\n",
    "            if memory:\n",
    "                x = x.contiguous().view(batch_size, n_layers, -1)\n",
    "                x = self.features[num_layer](x)\n",
    "                x = x.contiguous().view(batch_size, -1)\n",
    "                num_layer += 1\n",
    "              \n",
    "            # RNN layer\n",
    "            else:\n",
    "                out_features = []\n",
    "                for i in range(len(mask)):\n",
    "                    if double:\n",
    "                        landmarks = x[:,:,mask[i]].view(batch_size, n_layers, -1)\n",
    "                        landmarks = self.features[num_layer+1][i](self.features[num_layer][i](landmarks))\n",
    "\n",
    "                    else:\n",
    "                        landmarks = x[:,:,mask[i]].view(batch_size, n_layers, -1)\n",
    "                        landmarks = self.features[num_layer][i](landmarks)\n",
    "\n",
    "                    out_features.append(landmarks)\n",
    "                    \n",
    "                if double:\n",
    "                    num_layer += 2\n",
    "                else:\n",
    "                    num_layer += 1\n",
    "\n",
    "                x = torch.stack(out_features).permute(1,2,0,3)\n",
    "                \n",
    "        # classification\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d or type(m) == nn.Conv3d:\n",
    "        nn.init.xavier_normal(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This is where you chose the hierachy that you want.\n",
    "#arr = np.load('new_tree.npy')\n",
    "#arr = manual_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Builds model based on hierachical tree that was given, the number are slightly arbitrary, they are mainly to reproduce the dimensions of the original PHRNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_config = []\n",
    "for layer in range(arr.shape[1] - 1):\n",
    "    \n",
    "    # if not last layer\n",
    "    max_cluster = np.max(arr[:, layer+1]) + 1 \n",
    "    masks = []\n",
    "    # get mask for all cluster\n",
    "    for cluster in range(max_cluster):\n",
    "        masks.append(np.unique(arr[np.equal(arr[:,layer+1], cluster), layer]))\n",
    "    \n",
    "    if max_cluster <= 4:\n",
    "        double = True\n",
    "    else:\n",
    "        double = False\n",
    "    \n",
    "    # if last layer\n",
    "    if layer == arr.shape[1] - 2:\n",
    "        memory = True\n",
    "        h_size = 80\n",
    "        \n",
    "    else:\n",
    "        memory = False\n",
    "        h_size = int(450/(1 + 2*max_cluster))\n",
    "        \n",
    "    my_config.append((masks, h_size, 3, double, memory))\n",
    "    \n",
    "model = Flexible(my_config, 49, N_classes, use_mask=True)\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other configurations, run this script instead if you want to compare with the original PHRNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_masks = [np.array(range(34,71+1)), # eyebrows + nose\n",
    "              np.array(range(72,83+1)), # left eye\n",
    "              np.array(range(84,95+1)), # right eye\n",
    "              np.concatenate([np.array(range(96,109+1)), np.array(range(120,129+1))]), # upper lip\n",
    "              np.concatenate([np.array(range(110,119+1)), np.array(range(130,135+1))]) # lower lip\n",
    "             ]\n",
    "\n",
    "init_masks_kao = [np.array(range(34,53+1)), # eyebrows\n",
    "                  np.array(range(72,95+1)), # eyes\n",
    "                  np.array(range(54,71+1)), # nose\n",
    "                  np.array(range(96,135+1)) # mouth\n",
    "                 ]\n",
    "\n",
    "# for 49 landmarks\n",
    "init_masks_kao = [np.array(range(0,20)), # eyebrows\n",
    "                  np.array(range(38,60)), # eyes\n",
    "                  np.array(range(20,38)), # nose\n",
    "                  np.array(range(60,98)) # mouth\n",
    "                 ]\n",
    "\n",
    "# for each layer : mask/join, hidden_size, length of sequence, is double ?, has memory ?\n",
    "my_config = [\n",
    "       (init_masks, 30, 3, False, False),\n",
    "       ([[0],[1,2],[3,4]], 60, 3, True, False),\n",
    "       ([[0,1],[0,2]], 90, 3, True, False),\n",
    "       ([[0,1],[0,2]], 80, 3, False, True)\n",
    "]\n",
    "\n",
    "kao_config = [\n",
    "    (init_masks_kao, 30, 3, False, False),\n",
    "    ([[0,1],[2],[3]], 60, 3, True, False),\n",
    "    ([[0,1],[1,2]], 90, 3, True, False),\n",
    "    ([[0,1],[1,2]], 80, 3, False, True)\n",
    "]\n",
    "\n",
    "model = Flexible(kao_config, 49, N_classes)\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = model.parameters()\n",
    "\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(parameters, lr=0.001, weight_decay=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, _, train_acc, train_loss, val_acc, val_loss = train_model(model, criterion, optimizer, k=20, alpha=1.5, \n",
    "                                                                 num_epochs=1000, min_epoch=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = test_model(model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_folder = 'model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of pytorch 0.3.1, it is not possible to save bidirectionnal RNN hidden states weights with the regular save function, thus the whole model needs to be saved altogether. This means that loading the model in other scripts will require the source code of the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path = os.path.join(save_folder, 'manual_' + str(fold) + '.pt')\n",
    "torch.save(model, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bilstm = torch.load(os.path.join(save_folder, 'test_' + str(fold) + '.pt'))\n",
    "\n",
    "if use_gpu:\n",
    "    bilstm = bilstm.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = test_model(model, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot accuracy and loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better visualize the accuracy/loss, it is recommended to take the moving average instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = len(train_acc)\n",
    "window_width = 20\n",
    "\n",
    "cumsum_vec = np.cumsum(np.insert(train_acc, 0, 0)) \n",
    "ma_vec_train = (cumsum_vec[window_width:] - cumsum_vec[:-window_width]) / window_width\n",
    "\n",
    "cumsum_vec = np.cumsum(np.insert(val_acc, 0, 0)) \n",
    "ma_vec_val = (cumsum_vec[window_width:] - cumsum_vec[:-window_width]) / window_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(range(window_width,n_epochs+1), ma_vec_train, color='r', label='training')\n",
    "plt.plot(range(window_width,n_epochs+1), ma_vec_val, color='b', label='validation')\n",
    "#plt.plot(range(n_epochs), train_acc,color='r', label='training')\n",
    "#plt.plot(range(n_epochs), val_acc,color='b', label='validation')\n",
    "plt.grid(color='k', linestyle='-', linewidth=1)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('PHRNN training')\n",
    "pylab.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "#plt.plot(range(window_width,1001), ma_vec_train, color='r', label='training')\n",
    "#plt.plot(range(window_width,1001),ma_vec_val, color='b', label='validation')\n",
    "plt.plot(range(n_epochs), train_loss, color='r', label='training')\n",
    "plt.plot(range(n_epochs), val_loss, color='b', label='validation')\n",
    "plt.grid(color='k', linestyle='-', linewidth=1)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('PHRNN training')\n",
    "pylab.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "save_folder = 'model'\n",
    "save_path = os.path.join(save_folder, 'phrnn.pt')\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_accuracy = []\n",
    "save_folder = 'model'\n",
    "\n",
    "for fold in range(K):\n",
    "    \n",
    "    print('Starting fold ' + str(fold) + ' ...')\n",
    "    \n",
    "    # reassign datasets to training, validation and testing\n",
    "    training_folds = [x for x in range(K) if x is not fold]\n",
    "    validation_fold = random.choice(training_folds)\n",
    "    training_folds = [x for x in training_folds if x is not validation_fold]\n",
    "    \n",
    "    cross_datasets = {}\n",
    "    cross_datasets['train'] = torch.utils.data.ConcatDataset([training_datasets[k_folders[k]] \n",
    "                                                              for k in training_folds])\n",
    "    cross_datasets['val'] = validation_datasets[k_folders[validation_fold]]\n",
    "    \n",
    "    cross_datasets['test'] = validation_datasets[k_folders[fold]]\n",
    "\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(cross_datasets[x], batch_size=32,\n",
    "                                                 shuffle=True, num_workers=8)\n",
    "                  for x in ['train', 'val', 'test']}\n",
    "    dataset_sizes = {x: len(cross_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "    \n",
    "    # init model\n",
    "    model = Flexible(kao_config, 49, N_classes, use_mask=True)\n",
    "    model.apply(init_weights)\n",
    "    \n",
    "    # set up optimizer\n",
    "    parameters = model.parameters()\n",
    "\n",
    "    if use_gpu:\n",
    "        model = model.cuda()\n",
    "\n",
    "    optimizer = optim.Adamax(parameters, lr=0.001)\n",
    "\n",
    "    # train model\n",
    "    model, val_accuracy, train_acc, train_loss, val_acc, val_loss = train_model(model, criterion, optimizer, \n",
    "                                                                                k=20, alpha=1.5, num_epochs=1000, min_epoch=200)\n",
    "    test_loss, test_accuracy, conf = test_model(model, criterion)\n",
    "    \n",
    "    # save model\n",
    "    save_path = os.path.join(save_folder, 'kaohai_oulu' + str(fold) + '.pt')\n",
    "    #torch.save(model.state_dict(), save_path)\n",
    "    torch.save(model, save_path)\n",
    "    del model\n",
    "    \n",
    "    \n",
    "    print('Finished fold ' + str(fold) + ' with validation accuracy of ' + str(val_accuracy))\n",
    "    k_accuracy.append(test_accuracy)\n",
    "\n",
    "print('Mean value of test accuracy over ' + str(K) + '-fold crossvalidation is: ' \n",
    "      + str(sum(k_accuracy) / float(len(k_accuracy))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.boxplot(k_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_accuracy = []\n",
    "save_folder = 'model'\n",
    "conf_math = np.zeros((N_classes, N_classes))\n",
    "\n",
    "for fold in range(K):\n",
    "    print('Starting fold ' + str(fold) + ' ...')\n",
    "    \n",
    "    # reassign datasets to training, validation and testing\n",
    "    training_folds = [x for x in range(K) if x != fold]\n",
    "    validation_fold = random.choice(training_folds)\n",
    "    training_folds = [x for x in training_folds if x is not validation_fold]\n",
    "    \n",
    "    cross_datasets = {}\n",
    "    cross_datasets['train'] = torch.utils.data.ConcatDataset([training_datasets[k_folders[k]] \n",
    "                                                              for k in training_folds])\n",
    "    cross_datasets['val'] = validation_datasets[k_folders[validation_fold]]\n",
    "    \n",
    "    cross_datasets['test'] = validation_datasets[k_folders[fold]]\n",
    "\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(cross_datasets[x], batch_size=64,\n",
    "                                                 shuffle=True, num_workers=4)\n",
    "                  for x in ['train', 'val', 'test']}\n",
    "    dataset_sizes = {x: len(cross_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "        \n",
    "    model = torch.load(os.path.join(save_folder, 'manual_oulu' + str(fold) + '.pt'))\n",
    "    model.eval()\n",
    "    \n",
    "    if use_gpu:\n",
    "        model = model.cuda()\n",
    "    \n",
    "    test_loss, test_accuracy, conf = test_model(model, criterion)\n",
    "    conf_math += conf\n",
    "    k_accuracy.append(test_accuracy)\n",
    "    \n",
    "    del model\n",
    "    \n",
    "print('Mean value of test accuracy over ' + str(K) + '-fold cr_ossvalidation is: ' \n",
    "      + str(sum(k_accuracy) / float(len(k_accuracy))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf_math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    #plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(classes.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(conf_math, classes=list(classes.values()), normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
