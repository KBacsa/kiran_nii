{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# basic\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "from tqdm import tqdm\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# custom\n",
    "from affect_loader import AffectFolder\n",
    "import tvgg\n",
    "import tdense\n",
    "import tresnet\n",
    "from custom_models import DTAN, Zhang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_frames = 12\n",
    "batch_size = 64\n",
    "img_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load paths into dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the labels are different from dataset to dataset, part of the cleaning has to be done manually and the pretraining has to be done differently depending on the target training dataset. The current parameters are set to use AffectNet as pretraining for a training on CK+."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_path = os.path.join('/home', 'nii', 'Documents', 'AffectNet')\n",
    "list_path = os.path.join(root_path, 'Manually_Annotated_file_lists')\n",
    "train_name = 'training.csv'\n",
    "val_name = 'validation.csv'\n",
    "training_df = pd.read_csv(os.path.join(list_path, train_name))\n",
    "val_df = pd.read_csv(os.path.join(list_path, val_name))\n",
    "\n",
    "# CK+ classes =  {0:'anger', 1:'contempt', 2:'disgust', 3:'fear', 4:'happy', 5:'sadness', 6:'surprise'}\n",
    "# Oulu-CASIA classes = classes =  {0:'anger', 1:'disgust', 2:'fear', 3:'happy', 4:'sadness', 5:'surprise'}\n",
    "# AffectNet classes : 0: neutral, 1: happy, 2: sad, 3: surprise 4: fear, 5: disgust, 6: anger\n",
    "    # 7: contempt, 8: none, 9:uncertain, 10:non-face\n",
    "# map 1->4, 2->5, 3->6, 4->3, 5->2, 6->0, 7->1, discard 0,8,9,10\n",
    "# map 1->3, 2->4, 3->5, 4->2, 5->1, 6->0, discard 0,7,8,9,10\n",
    "\n",
    "aff_2_ck = {1:4, 2:5, 3:6, 4:3, 5:2, 6:0, 7:1}\n",
    "*aff_2_ou = {1:3, 2:4, 3:5, 4:2, 5:1, 6:0}\n",
    "non_emotions = [0,8,9,10]\n",
    "#non_emotions = [0,7,8,9,10]\n",
    "\n",
    "training_df = training_df[~training_df['expression'].isin(non_emotions)].dropna()\n",
    "training_df.expression = training_df.expression.map(aff_2_ck)\n",
    "val_df = val_df[~val_df['expression'].isin(non_emotions)]\n",
    "val_df.expression = val_df.expression.map(aff_2_ck)\n",
    "\n",
    "# split into val and test\n",
    "length = len(val_df)\n",
    "samples = random.sample(range(length), length)\n",
    "val_samples = samples[:int(length/2)]\n",
    "test_samples = samples[int(length/2):]\n",
    "test_df = val_df.iloc[test_samples]\n",
    "val_df = val_df.iloc[val_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make image loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = os.path.join(root_path, 'Manually_Annotated_Images')\n",
    "\n",
    "sets = ['train', 'val', 'test']\n",
    "dataframes = {'train': training_df, 'val': val_df, 'test': test_df}\n",
    "\n",
    "data_transforms = {'train': transforms.Compose(\n",
    "    [transforms.Resize((img_size,img_size)),\n",
    "     transforms.RandomHorizontalFlip(),\n",
    "     transforms.RandomRotation(15),\n",
    "     transforms.Grayscale(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, ), (0.225, ))]),\n",
    "                  \n",
    "                   'val': transforms.Compose(\n",
    "    [transforms.Resize((img_size,img_size)),\n",
    "     transforms.Grayscale(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, ), (0.225, ))]),\n",
    "     \n",
    "                    'test': transforms.Compose(\n",
    "    [transforms.Resize((img_size,img_size)),\n",
    "     transforms.Grayscale(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, ), (0.225, ))])}\n",
    "\n",
    "\n",
    "image_datasets = {x: AffectFolder(image_path, dataframes[x], transform=data_transforms[x])\n",
    "                  for x in sets}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in sets}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in sets}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=25, k=5, alpha=3):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_loss = 1e6\n",
    "    \n",
    "    stop_criterion = True\n",
    "    \n",
    "    train_accuracy = []\n",
    "    val_accuracy = []\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    \n",
    "    #for epoch in range(num_epochs):\n",
    "    epoch = 0\n",
    "    while stop_criterion:\n",
    "        #print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('Epoch {}'.format(epoch))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in tqdm(dataloaders[phase]):\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # reshape for all input filters\n",
    "                batch_size = inputs.size(0)\n",
    "                inputs = inputs.view(batch_size, 1, img_size, img_size).repeat(1, N_frames, 1, 1)\n",
    "                \n",
    "                # for DTAN\n",
    "                #inputs = inputs.view(batch_size, N_frames, 1, img_size, img_size)\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0] * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_accuracy.append(epoch_acc)\n",
    "                train_loss.append(epoch_loss)\n",
    "            else:\n",
    "                val_accuracy.append(epoch_acc)\n",
    "                val_loss.append(epoch_loss)\n",
    "                GL = 100 * (epoch_loss/best_loss - 1)\n",
    "                Pk = 1000 * (sum(train_loss[-k:]) / (k*min(train_loss[-k:])) - 1)\n",
    "                PQ = GL / Pk\n",
    "                \n",
    "                if PQ > alpha:\n",
    "                    stop_criterion = False\n",
    "                \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc >= best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "        epoch += 1\n",
    "\n",
    "        print()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_acc, train_accuracy, train_loss, val_accuracy, val_loss\n",
    "\n",
    "\n",
    "def test_model(model, criterion):\n",
    "    \n",
    "    model.train(False)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "\n",
    "    # Iterate over data.\n",
    "    for data in dataloaders['test']:\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        if use_gpu:\n",
    "            inputs = Variable(inputs.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # reshape for all input filters\n",
    "        batch_size = inputs.size(0)\n",
    "        inputs = inputs.view(batch_size, 1, img_size, img_size).repeat(1, N_frames, 1, 1)    \n",
    "            \n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # statistics\n",
    "        running_loss += loss.data[0] * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    total_loss = running_loss / dataset_sizes['test']\n",
    "    total_acc = running_corrects / dataset_sizes['test']\n",
    "\n",
    "    print('{} Loss: {:.4f} Acc: {:.4f}'.format('test', total_loss, total_acc))\n",
    "\n",
    "    return total_loss, total_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pytorch, to reinitialize a model, one must first delete it to clear the RAM/GPU memory, else more and more memory will be used to sustain multiple models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can pick from various models to use for spatial features extraction. Training should be done on GPU for increased speed, however debugging should be done on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model = tvgg.vgg11_bn(num_classes=6, n_frames=N_frames)\n",
    "model = tdense.densenet121(num_classes=7)\n",
    "#model = DTAN(n_frames=N_frames, n_classes=7)\n",
    "#model = Zhang(n_frames=N_frames, n_classes=7)\n",
    "#model = tresnet.resnet18(num_frames=N_frames, num_classes=7)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "#use_gpu = False\n",
    "parameters = model.parameters()\n",
    "\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(parameters, lr=0.001, weight_decay=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, _, train_acc, train_loss, val_acc, val_loss = train_model(model, criterion, optimizer, num_epochs=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = test_model(model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "save_folder = 'model'\n",
    "save_path = os.path.join(save_folder, 'dense.pt')\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(train_acc, color='r', label='training')\n",
    "plt.plot(val_acc, color='b', label='validation')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('VGG training')\n",
    "pylab.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(train_loss,color='r', label='training')\n",
    "plt.plot(val_loss,color='b', label='validation')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('VGG training')\n",
    "pylab.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
