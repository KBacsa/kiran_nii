{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is to finetune the pretrained CNN on the target dataset. This is not the joint finetuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# basic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import itertools\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "from tqdm import tqdm\n",
    "\n",
    "# machine learning\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# custom\n",
    "import video_loader\n",
    "import tvgg\n",
    "import tdense\n",
    "from custom_models import DTAN, Zhang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_frames = 12\n",
    "batch_size = 8\n",
    "img_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run one of the sections for the target training dataset. For loading videos in Pytorch, I made a single image loader class for all datasets. This turned out to be a bad idea, since every dataset has its own specificities, which has thus made the code bulky and unflexible. One possible improvement would be to make a separate class for each dataset, just as I have done for the fixed image datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AFEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes =  {0:'neutral', 1:'angry', 2:'disgust', 3:'fear', 4:'happy', 5:'sad', 6:'surprise'}\n",
    "N_frames = 12\n",
    "N_landmarks = 49\n",
    "N_classes = len(classes)\n",
    "\n",
    "# preprocessing\n",
    "data_dir = os.path.join('/home','nii','Documents','EmotiW_2018','Train_AFEW')\n",
    "data_dir_val = os.path.join('/home','nii','Documents','EmotiW_2018','Val_AFEW')\n",
    "\n",
    "data_transforms = transforms.Compose(\n",
    "    [transforms.Resize((64,64))])\n",
    "\n",
    "K = 10\n",
    "k_folders = ['set_' + str(idx) for idx in range(K)]   \n",
    "\n",
    "    \n",
    "training_datasets = {x: video_loader.VideoFolder(root=data_dir, image_folder='cropped_images', \n",
    "                                 label_folder='emotion', landmark_folder='landmarks',\n",
    "                                 fold=x, phase='train', img_type='jpg',\n",
    "                                 classes=classes, n_frames=N_frames, n_landmarks=N_landmarks,\n",
    "                                 transform=data_transforms, indexing=0,\n",
    "                                   are_subjects=False)\n",
    "                    for x in k_folders}\n",
    "\n",
    "\n",
    "validation_datasets = {x: video_loader.VideoFolder(root=data_dir, image_folder='cropped_images', \n",
    "                                 label_folder='emotion', landmark_folder='landmarks',\n",
    "                                 fold=x, phase='valid', img_type='jpg',\n",
    "                                 classes=classes, n_frames=N_frames,  n_landmarks=N_landmarks,\n",
    "                                 transform=data_transforms, indexing=0,\n",
    "                                     are_subjects=False)\n",
    "                    for x in k_folders}\n",
    "\n",
    "testing_datasets = {x: video_loader.VideoFolder(root=data_dir_val, image_folder='cropped_images', \n",
    "                                 label_folder='emotion', landmark_folder='landmarks',\n",
    "                                 fold=x, phase='test', img_type='jpg',\n",
    "                                 classes=classes, n_frames=N_frames,  n_landmarks=N_landmarks,\n",
    "                                 transform=data_transforms, indexing=0,\n",
    "                                     are_subjects=False)\n",
    "                    for x in k_folders}\n",
    "\n",
    "fold = 8\n",
    "\n",
    "training_folds = [x for x in range(K) if x != fold]\n",
    "validation_fold = fold\n",
    "\n",
    "cross_datasets = {}\n",
    "cross_datasets['train'] = torch.utils.data.ConcatDataset([training_datasets[k_folders[k]] \n",
    "                                                          for k in training_folds])\n",
    "cross_datasets['val'] = validation_datasets[k_folders[validation_fold]]\n",
    "\n",
    "cross_datasets['test'] = torch.utils.data.ConcatDataset([testing_datasets[k_folders[k]] \n",
    "                                                          for k in range(K)])\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(cross_datasets[x], batch_size=64, shuffle=True,\n",
    "                                              num_workers=4)\n",
    "              for x in ['train', 'val', 'test']}\n",
    "\n",
    "dataset_sizes = {x: len(cross_datasets[x]) for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vidshow(video, title=None):\n",
    "    fig, axes = plt.subplots(nrows=videos.size()[0], ncols=videos.size()[1], figsize=(20,20))\n",
    "    \n",
    "    #mean = np.array([0.485, 0.456, 0.406])\n",
    "    #std = np.array([0.229, 0.224, 0.225])\n",
    "    \n",
    "    for vid in range(videos.size()[0]):\n",
    "        sequence = videos[vid]\n",
    "        for frame in range(videos.size()[1]):\n",
    "            #im = sequence[frame].numpy().transpose((1, 2, 0))\n",
    "            im = np.squeeze(sequence[frame].numpy())\n",
    "            \n",
    "            # to original color\n",
    "            #im = std * im + mean\n",
    "            #im = np.clip(im, 0, 1)\n",
    "            \n",
    "            axes[vid][frame].imshow(im, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "videos[0,-1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "videos, classes, ld = next(iter(dataloaders['train']))\n",
    "vidshow(videos, ld)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CK+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes =  {0:'anger', 1:'contempt', 2:'disgust', 3:'fear', 4:'happy', 5:'sadness', 6:'surprise'}\n",
    "N_frames = 12\n",
    "N_classes = len(classes)\n",
    "N_landmarks = 68\n",
    "\n",
    "# preprocessing\n",
    "data_dir = os.path.join('/home','nii','Documents','CK+')\n",
    "\n",
    "data_transforms = transforms.Compose(\n",
    "    [transforms.Resize((64,64))])\n",
    "\n",
    "K = 10\n",
    "k_folders = ['set_' + str(idx) for idx in range(K)]\n",
    "\n",
    "    \n",
    "training_datasets = {x: video_loader.VideoFolder(root=data_dir, image_folder='cohn-kanade-images-crop', \n",
    "                                 label_folder='Emotion', landmark_folder='Landmarks_crop',\n",
    "                                 fold=x, phase='train', classes=classes, n_frames=N_frames, n_landmarks=N_landmarks,\n",
    "                                                 transform=data_transforms,\n",
    "                                 indexing=1)\n",
    "                    for x in k_folders}\n",
    "\n",
    "validation_datasets = {x: video_loader.VideoFolder(root=data_dir, image_folder='cohn-kanade-images-crop', \n",
    "                                 label_folder='Emotion', landmark_folder='Landmarks_crop',\n",
    "                                 fold=x, phase='valid', classes=classes, n_frames=N_frames, n_landmarks=N_landmarks,\n",
    "                                                   transform=data_transforms,\n",
    "                                 indexing=1)\n",
    "                    for x in k_folders}\n",
    "\n",
    "fold = 9\n",
    "\n",
    "training_folds = [x for x in range(K) if x != fold]\n",
    "validation_fold = random.choice(training_folds)\n",
    "training_folds = [x for x in training_folds if x is not validation_fold]\n",
    "\n",
    "cross_datasets = {}\n",
    "cross_datasets['train'] = torch.utils.data.ConcatDataset([training_datasets[k_folders[k]] \n",
    "                                                          for k in training_folds])\n",
    "cross_datasets['val'] = validation_datasets[k_folders[validation_fold]]\n",
    "\n",
    "cross_datasets['test'] = validation_datasets[k_folders[fold]]\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(cross_datasets[x], batch_size=batch_size, shuffle=True,\n",
    "                                              num_workers=4)\n",
    "              for x in ['train', 'val', 'test']}\n",
    "\n",
    "dataset_sizes = {x: len(cross_datasets[x]) for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oulu-CASIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes =  {0:'anger', 1:'disgust', 2:'fear', 3:'happy', 4:'sadness', 5:'surprise'}\n",
    "data_dir = os.path.join('/home','nii','Documents', 'OriginalImg', 'VL')\n",
    "N_frames = 12\n",
    "N_classes = len(classes)\n",
    "N_landmarks = 68\n",
    "\n",
    "data_transforms = transforms.Compose(\n",
    "    [transforms.Resize((64,64))])\n",
    "\n",
    "K = 10\n",
    "k_folders = ['set_' + str(idx) for idx in range(K)]\n",
    "    \n",
    "training_datasets = {x: video_loader.VideoFolder(root=data_dir, image_folder='Strong-crop', \n",
    "                                 label_folder='Strong-emotion', landmark_folder='Landmarks_crop',\n",
    "                                 fold=x, phase='train', classes=classes, img_type='jpeg', n_landmarks=N_landmarks,\n",
    "                                    n_frames=N_frames, transform=data_transforms)\n",
    "                    for x in k_folders}\n",
    "\n",
    "validation_datasets = {x: video_loader.VideoFolder(root=data_dir, image_folder='Strong-crop', \n",
    "                                 label_folder='Strong-emotion', landmark_folder='Landmarks_crop',\n",
    "                                 fold=x, phase='valid', classes=classes, img_type='jpeg', n_landmarks=N_landmarks,\n",
    "                                      n_frames=N_frames, transform=data_transforms)\n",
    "                    for x in k_folders}\n",
    "\n",
    "\n",
    "fold = 7\n",
    "\n",
    "training_folds = [x for x in range(K) if x != fold]\n",
    "validation_fold = random.choice(training_folds)\n",
    "training_folds = [x for x in training_folds if x is not validation_fold]\n",
    "\n",
    "cross_datasets = {}\n",
    "cross_datasets['train'] = torch.utils.data.ConcatDataset([training_datasets[k_folders[k]] \n",
    "                                                          for k in training_folds])\n",
    "cross_datasets['val'] = validation_datasets[k_folders[validation_fold]]\n",
    "\n",
    "cross_datasets['test'] = validation_datasets[k_folders[fold]]\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(cross_datasets[x], batch_size=32,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val', 'test']}\n",
    "\n",
    "dataset_sizes = {x: len(cross_datasets[x]) for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=25, k=5, alpha=0.2):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_loss = 1e6\n",
    "    \n",
    "    stop_criterion = True\n",
    "    \n",
    "    train_accuracy = []\n",
    "    val_accuracy = []\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    \n",
    "    #for epoch in range(num_epochs):\n",
    "    epoch = 0\n",
    "    while stop_criterion:\n",
    "        #print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('Epoch {}'.format(epoch))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                # get the inputs\n",
    "                inputs, labels, _ = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                b_s = inputs.size(0)\n",
    "                if b_s != 1:\n",
    "                    outputs = model(torch.squeeze(inputs))\n",
    "                else:\n",
    "                    outputs = model(torch.squeeze(inputs).unsqueeze(0))\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0] * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_accuracy.append(epoch_acc)\n",
    "                train_loss.append(epoch_loss)\n",
    "            else:\n",
    "                val_accuracy.append(epoch_acc)\n",
    "                val_loss.append(epoch_loss)\n",
    "                GL = 100 * (epoch_loss/best_loss - 1)\n",
    "                Pk = 1000 * (sum(train_loss[-k:]) / (k*min(train_loss[-k:])) - 1)\n",
    "                PQ = GL / Pk\n",
    "                \n",
    "                print('PQ = ' + str(PQ))\n",
    "                \n",
    "                if PQ > alpha or epoch == num_epochs:\n",
    "                    stop_criterion = False\n",
    "                \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc >= best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        epoch += 1\n",
    "        \n",
    "        print()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_acc, train_accuracy, train_loss, val_accuracy, val_loss\n",
    "\n",
    "\n",
    "def test_model(model, criterion):\n",
    "    \n",
    "    model.train(False)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    \n",
    "    truth = []\n",
    "    prediction = []\n",
    "\n",
    "    # Iterate over data.\n",
    "    for data in dataloaders['test']:\n",
    "        \n",
    "        # get the inputs\n",
    "        inputs, labels, _ = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        if use_gpu:\n",
    "            inputs = Variable(inputs.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        b_s = inputs.size(0)\n",
    "        \n",
    "        # forward\n",
    "        if b_s != 1:\n",
    "            outputs = model(torch.squeeze(inputs))\n",
    "        else:\n",
    "            outputs = model(torch.squeeze(inputs).unsqueeze(0))\n",
    "        \n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # statistics\n",
    "        running_loss += loss.data[0] * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        truth.extend(labels.cpu().data.numpy().tolist())\n",
    "        prediction.extend(preds.cpu().numpy().tolist())\n",
    "\n",
    "    total_loss = running_loss / dataset_sizes['test']\n",
    "    total_acc = running_corrects / dataset_sizes['test']\n",
    "\n",
    "    print('{} Loss: {:.4f} Acc: {:.4f}'.format('test', total_loss, total_acc))\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(truth, prediction, labels=list(range(N_classes)))\n",
    "\n",
    "    return total_loss, total_acc, cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_folder = 'model'\n",
    "model = tvgg.vgg11_bn(num_classes=N_classes, n_frames=N_frames)\n",
    "#model = tvgg.vgg16_bn(num_classes=7, n_frames=N_frames)\n",
    "#model = tdense.densenet121(num_classes=N_classes)\n",
    "#model = Zhang(n_frames=N_frames, n_classes=7)\n",
    "#model.load_state_dict(torch.load(os.path.join(save_folder, 'zhang.pt')))\n",
    "model.load_state_dict(torch.load(os.path.join(save_folder, 'vgg11.pt')))\n",
    "#model.load_state_dict(torch.load(os.path.join(save_folder, 'dense.pt')))\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "#use_gpu = False\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "parameters = model.parameters()\n",
    "\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adamax(parameters, lr=0.001, weight_decay=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, _, train_acc, train_loss, val_acc, val_loss = train_model(model, criterion, optimizer, num_epochs=200, k=10, alpha=2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_loss, test_accuracy, conf = test_model(model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(train_acc,color='r', label='training')\n",
    "plt.plot(val_acc,color='b', label='validation')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('VGG training')\n",
    "pylab.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(train_loss,color='r', label='training')\n",
    "plt.plot(val_loss,color='b', label='validation')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('DTAN training')\n",
    "pylab.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "save_folder = 'model'\n",
    "save_path = os.path.join(save_folder, 'vgg_finetune_afew6.pt')\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold crossvalidation finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_accuracy = []\n",
    "save_folder = 'model'\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "for fold in range(K):\n",
    "    \n",
    "    print('Starting fold ' + str(fold) + ' ...')\n",
    "    \n",
    "    # reassign datasets to training, validation and testing\n",
    "    training_folds = [x for x in range(K) if x != fold]\n",
    "    validation_fold = random.choice(training_folds)\n",
    "    training_folds = [x for x in training_folds if x is not validation_fold]\n",
    "\n",
    "    cross_datasets = {}\n",
    "    cross_datasets['train'] = torch.utils.data.ConcatDataset([training_datasets[k_folders[k]] \n",
    "                                                              for k in training_folds])\n",
    "    cross_datasets['val'] = validation_datasets[k_folders[validation_fold]]\n",
    "\n",
    "    cross_datasets['test'] = validation_datasets[k_folders[fold]]\n",
    "    \n",
    "    dataloaders = {x: torch.utils.data.DataLoader(cross_datasets[x], batch_size=batch_size,\n",
    "                                                 shuffle=True, num_workers=4)\n",
    "                  for x in ['train', 'val', 'test']}\n",
    "    dataset_sizes = {x: len(cross_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "    \n",
    "    # init model\n",
    "    model = tvgg.vgg11_bn(num_classes=N_classes, n_frames=N_frames)\n",
    "    model.load_state_dict(torch.load(os.path.join(save_folder, 'vgg11.pt')))\n",
    "    #model = tdense.densenet121(num_classes=7)\n",
    "    #model.load_state_dict(torch.load(os.path.join(save_folder, 'dense.pt')))\n",
    "    \n",
    "    # set up optimizer\n",
    "    parameters = model.parameters()\n",
    "\n",
    "    if use_gpu:\n",
    "        model = model.cuda()\n",
    "\n",
    "    optimizer = optim.Adamax(parameters, lr=0.001, weight_decay=5e-5)\n",
    "\n",
    "    # train model\n",
    "    model, val_accuracy, train_acc, train_loss, val_acc, val_loss = train_model(model, criterion, optimizer, \n",
    "                                                                                num_epochs=300, k=20, alpha=2.0)\n",
    "    test_loss, test_accuracy, conf = test_model(model, criterion)\n",
    "    \n",
    "    # save model\n",
    "    save_path = os.path.join(save_folder, 'vgg_finetune' + str(fold) + '.pt')\n",
    "    #save_path = os.path.join(save_folder, 'dense_finetune' + str(fold) + '.pt')\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    \n",
    "    print('Finished fold ' + str(fold) + ' with validation accuracy of ' + str(val_accuracy))\n",
    "    k_accuracy.append(test_accuracy)\n",
    "    del model\n",
    "\n",
    "print('Mean value of test accuracy over ' + str(K) + '-fold crossvalidation is: '\n",
    "      + str(sum(k_accuracy) / float(len(k_accuracy))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.boxplot(k_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-val test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_accuracy = []\n",
    "conf_math = np.zeros((N_classes, N_classes))\n",
    "\n",
    "for fold in range(K):\n",
    "    print('Starting fold ' + str(fold) + ' ...')\n",
    "    \n",
    "    # reassign datasets to training, validation and testing\n",
    "    training_folds = [x for x in range(K) if x != fold]\n",
    "    validation_fold = random.choice(training_folds)\n",
    "    training_folds = [x for x in training_folds if x is not validation_fold]\n",
    "    \n",
    "    cross_datasets = {}\n",
    "    cross_datasets['train'] = torch.utils.data.ConcatDataset([training_datasets[k_folders[k]] \n",
    "                                                              for k in training_folds])\n",
    "    cross_datasets['val'] = validation_datasets[k_folders[validation_fold]]\n",
    "    \n",
    "    cross_datasets['test'] = validation_datasets[k_folders[fold]]\n",
    "\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(cross_datasets[x], batch_size=64,\n",
    "                                                 shuffle=True, num_workers=4)\n",
    "                  for x in ['train', 'val', 'test']}\n",
    "    dataset_sizes = {x: len(cross_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "        \n",
    "    #tvgg = tdense.densenet121(num_classes=7)\n",
    "    #tvgg.load_state_dict(torch.load(os.path.join(save_folder, 'dense_finetune' + str(fold) + '.pt')))\n",
    "    \n",
    "    model = tvgg.vgg11_bn(num_classes=N_classes, n_frames=N_frames)\n",
    "    model.load_state_dict(torch.load(os.path.join(save_folder, 'vgg_finetune' + str(fold) + '.pt')))\n",
    "    model.eval()\n",
    "    \n",
    "    if use_gpu:\n",
    "        model = model.cuda()\n",
    "    \n",
    "    test_loss, test_accuracy, conf = test_model(model, criterion)\n",
    "    conf_math += conf\n",
    "    k_accuracy.append(test_accuracy)\n",
    "    \n",
    "    del model\n",
    "    \n",
    "print('Mean value of test accuracy over ' + str(K) + '-fold crossvalidation is: ' \n",
    "      + str(sum(k_accuracy) / float(len(k_accuracy))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conf_math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    #plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(conf_math, classes=list(classes.values()), normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "    for i, data in enumerate(dataloaders['test']):\n",
    "        inputs, labels, _ = data\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        outputs = model(torch.squeeze(inputs))\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "        for j in range(inputs.size()[0]):\n",
    "            images_so_far += 1\n",
    "            ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "            ax.axis('off')\n",
    "            ax.set_title('predicted: {} label: {}'.format(classes[preds[j]], classes[labels.data[j]]))\n",
    "            plt.imshow(torch.squeeze(inputs.cpu().data[j,-1]), cmap='gray')\n",
    "\n",
    "            if images_so_far == num_images:\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = tvgg.vgg11_bn(num_classes=N_classes, n_frames=N_frames)\n",
    "model.load_state_dict(torch.load(os.path.join(save_folder, 'vgg_finetune' + str(fold) + '.pt')))\n",
    "if use_gpu:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
