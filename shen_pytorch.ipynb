{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph inference code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning** Most of this code is experimental. To be able to apply the graph inference process, the data is heavily subsampled, and therefore much of the information is lost. Because of this, the script main need to be run several times with different subsamplings before reaching coherent results. Moreover, the clustering techniques that have been applied are 'ad hoc' and can definetly be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# basic\n",
    "import os\n",
    "import time\n",
    "import itertools  \n",
    "import numpy as np\n",
    "from difflib import SequenceMatcher\n",
    "from collections import defaultdict\n",
    "\n",
    "# machine learning\n",
    "from scipy.linalg import block_diag\n",
    "from scipy import linalg\n",
    "from scipy import signal\n",
    "import scipy.fftpack\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "from scipy.sparse.linalg import expm\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import peakutils\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import rgb2hex, colorConverter\n",
    "hsv = plt.get_cmap('hsv')\n",
    "from tqdm import tqdm\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# custom\n",
    "import video_loader\n",
    "\n",
    "# multi-threading\n",
    "from multiprocessing.dummy import Pool as ThreadPool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes =  {0:'anger', 1:'contempt', 2:'disgust', 3:'fear', 4:'happy', 5:'sadness', 6:'surprise'}\n",
    "N_frames = 20\n",
    "N_landmarks = 68 \n",
    "N_classes = len(classes)\n",
    "\n",
    "# preprocessing\n",
    "data_dir = os.path.join('/home','nii','Documents','CK+')\n",
    "\n",
    "data_transforms = transforms.Compose(\n",
    "    [transforms.Resize((64,64))])\n",
    "\n",
    "K = 10\n",
    "k_folders = ['set_' + str(idx) for idx in range(K)]   \n",
    "\n",
    "    \n",
    "training_datasets = {x: video_loader.VideoFolder(root=data_dir, image_folder='cohn-kanade-images-crop', \n",
    "                                 label_folder='Emotion', landmark_folder='Landmarks_crop',\n",
    "                                 fold=x, phase='train', \n",
    "                                 classes=classes, n_frames=N_frames, n_landmarks=N_landmarks,\n",
    "                                 transform=data_transforms, indexing=1)\n",
    "                    for x in k_folders}\n",
    "\n",
    "validation_datasets = {x: video_loader.VideoFolder(root=data_dir, image_folder='cohn-kanade-images-crop', \n",
    "                                 label_folder='Emotion', landmark_folder='Landmarks_crop',\n",
    "                                 fold=x, phase='valid', \n",
    "                                 classes=classes, n_frames=N_frames, n_landmarks=N_landmarks,\n",
    "                                 transform=data_transforms, indexing=1)\n",
    "                    for x in k_folders}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "folds = [x for x in range(K)]\n",
    "\n",
    "dataset = torch.utils.data.ConcatDataset([validation_datasets[k_folders[k]] \n",
    "                                                          for k in folds])\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True,\n",
    "                                              num_workers=4)\n",
    "\n",
    "dataset_size = len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "videos, classes, land = next(iter(dataloader))\n",
    "#landmarks = land.view(batch_size,N_frames,2*N_landmarks).permute(0,2,1)#.contiguous().view(2*N_landmarks, -1)\n",
    "Y = land.view(batch_size,N_frames,2*N_landmarks).permute(2,1,0).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_landmarks():\n",
    "    y_list = []\n",
    "    for data in dataloader:\n",
    "        _, _, land = data\n",
    "        batch_size = land.size(0)\n",
    "        land = land.view(batch_size, N_frames, 2*N_landmarks).permute(2,0,1).contiguous().view(2*N_landmarks, -1)\n",
    "        y_list.append(land)\n",
    "        \n",
    "    return torch.cat(y_list, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = get_landmarks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.ones((Y.size(0), 1),  dtype=bool)\n",
    "mask[:34] = False\n",
    "mask[120:122] = False\n",
    "mask[128:130] = False\n",
    "Y = Y[np.where(mask)[0],:]\n",
    "N_landmarks = 49\n",
    "Y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Y.numpy()[63,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ym = np.array(Y.numpy())\n",
    "for i in range(2*N_landmarks):\n",
    "    signal = Ym[i,:]\n",
    "    yf = scipy.fftpack.fft(signal)\n",
    "    peakind = peakutils.indexes(yf, thres=0.02/max(yf), min_dist=100)\n",
    "    yf[peakind] = 0\n",
    "    Ym[i,:] = np.real(scipy.fftpack.ifft(yf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_sig = abs(scipy.fftpack.fftshift(scipy.fftpack.fft(Y.numpy().reshape(2*N_landmarks, -1, order='F')[63,:])))\n",
    "plt.plot(np.array(range(len(fft_sig))) - int(len(fft_sig)/2), fft_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peakind = peakutils.indexes(fft_sig, thres=0.02/max(fft_sig), min_dist=100)\n",
    "fft_filt = np.array(fft_sig)\n",
    "fft_filt[peakind] = 0\n",
    "plt.plot(np.array(range(len(fft_filt))) - int(len(fft_filt)/2), fft_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_kernel_maps(Y, N, T, L):\n",
    "    l_list = []\n",
    "    d_list = []\n",
    "\n",
    "    # for all orders\n",
    "    for l in range(L):\n",
    "        k_list = []\n",
    "        # for all landmarks\n",
    "        for i in range(N):\n",
    "            y = Y[i,:]\n",
    "            sigma = np.std(y)\n",
    "            K_t = np.zeros((T, T))\n",
    "            # at all time steps\n",
    "            for t in range(T):\n",
    "                for tau in range(T):\n",
    "                    # landmarks that are poorly detected\n",
    "                    if sigma != 0:\n",
    "                        shift = tau - l\n",
    "                        if not (shift < 0 or shift >= T):\n",
    "                            # compute kernel\n",
    "                            if shift != t:\n",
    "                                #K_t[t, tau] = np.exp(-abs(y[t]-y[shift])**2 / (2*sigma**2))\n",
    "                                K_t[t, tau] = (y[t]*y[shift] + 1)**2\n",
    "\n",
    "            k_list.append(K_t)\n",
    "\n",
    "        K_l = np.concatenate((k_list), 1)\n",
    "        D_l = block_diag(*k_list)\n",
    "\n",
    "        l_list.append(K_l)\n",
    "        d_list.append(D_l)\n",
    "\n",
    "    K = np.concatenate((l_list), 1)\n",
    "    D = block_diag(*d_list)\n",
    "    \n",
    "    return K, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = torch.DoubleTensor(Ym)\n",
    "slices = int(Y.size(1)*0.004) \n",
    "Yf = Y.unfold(1, slices, 1)[:,0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kernel map\n",
    "N = N_landmarks * 2\n",
    "T = Yf.shape[1]\n",
    "L = 2\n",
    "\n",
    "K, D = compute_kernel_maps(Yf, N, T, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Yf[63])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = lil_matrix(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.spy(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "Gamma = np.zeros((N*T*L, N))\n",
    "Xi = np.zeros((N*T*L, N))\n",
    "k = 0\n",
    "\n",
    "Kn = {}\n",
    "Dn = {}\n",
    "\n",
    "# filtered kernel maps\n",
    "for j in range(0, N):\n",
    "    Ij = np.array(range(j*T , (j+1)*T))\n",
    "    Ijk = np.array([x for x in np.array(range(0 , N*T)) if x not in Ij])\n",
    "    mask_k = np.ones(N*T, dtype=bool)\n",
    "    mask_k[Ijk] = False\n",
    "    \n",
    "    Ijd = np.array(Ijk)\n",
    "    for m in range(1, L):\n",
    "        Ijd = np.concatenate((Ijd, Ijk + m*N*T))\n",
    "        \n",
    "    mask_d = np.ones(N*T*L, dtype=bool)\n",
    "    mask_d[Ijd] = False\n",
    "    \n",
    "    #Kj = K[:, Ijk]\n",
    "    Kj = np.array(K)\n",
    "    Kj[:, mask_d] = 0\n",
    "    Kn[j] = Kj\n",
    "    \n",
    "    #Dj = D[Ijk, :]\n",
    "    #Dj = Dj[:, Ijd]\n",
    "    Dj = lil_matrix(D)\n",
    "    Dj[mask_d, :] = 0\n",
    "    Dj[:, mask_d] = 0\n",
    "    Dn[j] = Dj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ki = torch.from_numpy(K**(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def block_shrinkage(z, lamb):\n",
    "    return torch.clamp(z - lamb, min=0) / (z.norm() + 1e-6)\n",
    "    #return z * torch.max(z.norm() - lamb, 0) / (z.norm() + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parallel(j, rho, lamb):\n",
    "    # fetch variables\n",
    "    Dj = torch.from_numpy(Dn[j].toarray())\n",
    "    Kj = torch.from_numpy(Kn[j])\n",
    "    Ki = torch.from_numpy(K**(0.5))\n",
    "    xi = torch.from_numpy(Xi[:,j])\n",
    "    y = torch.from_numpy(Yf[j,:])\n",
    "    gamma = torch.from_numpy(Gamma[:,j])\n",
    "    \n",
    "    if use_gpu:\n",
    "        Dj = Dj.cuda()\n",
    "        Kj = Kj.cuda()\n",
    "        Ki = Ki.cuda()\n",
    "        xi = xi.cuda()\n",
    "        y = y.cuda()\n",
    "        gamma = gamma.cuda()\n",
    "        \n",
    "    # first step\n",
    "    q = rho * Dj**0.5 @ gamma + Kj.transpose(1,0) @ y - Dj**0.5 @ xi\n",
    "    \n",
    "    # prevent matrix from being singular\n",
    "    X = Kj.transpose(1,0) @ Kj + rho * Dj\n",
    "    \n",
    "    #X[np.diag_indices_from(X)] += 1e-4\n",
    "    v = torch.diag(X) + 1e-4\n",
    "    mask = torch.diag(torch.ones_like(v))\n",
    "    X = mask*torch.diag(v) + (1. - mask)*X\n",
    "    \n",
    "    # second step\n",
    "    #alpha = np.linalg.inv(X) @ q\n",
    "    #X_LU = torch.btrifact(X)\n",
    "    #alpha = torch.btrisolve(q, *X_LU)\n",
    "    alpha = X.inverse() @ q\n",
    "    \n",
    "    # third step\n",
    "    for i in range(N):\n",
    "        for l in range(1,L):\n",
    "            index = list(range(i*T+N*l, (i+1)*T+N*l))\n",
    "            gamma[index] = block_shrinkage(Ki[:,index] @ alpha[index].transpose(-1,0) + xi[index]/rho, lamb)\n",
    "            \n",
    "    return alpha, gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "use_gpu = True\n",
    "Gamma = np.zeros((N*T*L, N))\n",
    "Xi = np.zeros((N*T*L, N))\n",
    "W = np.zeros((N*T*L, N))\n",
    "k = 0\n",
    "\n",
    "# hyper-parameters\n",
    "rho = 1e-3\n",
    "lamb = 0.01\n",
    "\n",
    "start_time = time.time()\n",
    "for k in range(3):\n",
    "    for j in range(0, N):\n",
    "        print('landmark ' + str(j))\n",
    "        alpha, gamma = parallel(j, rho, lamb)\n",
    "        W[:,j] = alpha\n",
    "        Gamma[:,j] = gamma\n",
    "\n",
    "    Xi += rho * (D.power(0.5) @ W - Gamma)\n",
    "    \n",
    "    print('Norm of W is : ' + str(np.linalg.norm(W)))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2,30))\n",
    "plt.imshow(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_0 = W[:N*T,:]\n",
    "W_0 = abs(W_0.reshape(T,N,N)).mean(axis=0)\n",
    "W_0[W_0 < 0.00000001] = 0\n",
    "np.fill_diagonal(W_0, 0)\n",
    "plt.imshow(W_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "W_1 = W[N*T:N*T*L,:]\n",
    "W_1 = abs(W_1.reshape(T,N,N)).mean(axis=0)\n",
    "W_1[W_1 < 0.000001] = 0\n",
    "np.fill_diagonal(W_1, 0)\n",
    "#W_1 = (W_1.T + W_1)/2\n",
    "plt.imshow(W_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = np.array(W_1)\n",
    "# bibliometric symmetrization\n",
    "U_d = weights @ weights.T + weights.T @ weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# degree-discounted symmetrization\n",
    "weights = np.array(W_1)\n",
    "d_o = np.sum(weights,axis=0) \n",
    "d_o[d_o == 0] = 1\n",
    "D_o = np.diag(d_o**-0.5)\n",
    "\n",
    "d_i = np.sum(weights,axis=1) \n",
    "d_i[d_i == 0] = 1\n",
    "D_i = np.diag(d_i**-0.5)\n",
    "\n",
    "B_d = D_o @ weights @ D_i @ weights.T @ D_o\n",
    "C_d = D_i @ weights.T @ D_o @ weights @ D_i\n",
    "U_d = B_d + C_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(U_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = np.array(U_d)\n",
    "degrees = np.sum(weights,axis=0)\n",
    "degrees[degrees == 0] = 1\n",
    "laplacian = np.diag(degrees**-0.5) @ (np.diag(degrees) - weights) @ np.diag(degrees**-0.5)\n",
    "eigenvalues, eigenvectors = linalg.eigh(laplacian)\n",
    "plt.plot(eigenvalues[:20], '.-', markersize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(eigenvalues[2:20]/eigenvalues[1:19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Face = np.load('face_positions.npy')\n",
    "mask = np.ones((Face.shape[0], ),  dtype=bool)\n",
    "mask[:17] = False\n",
    "mask[60] = False\n",
    "mask[64] = False\n",
    "Face = Face[mask,:]\n",
    "num_features = 7\n",
    "V = eigenvectors[:,1:num_features+1]  #* (eigenvalues[1:num_features+1]**2)\n",
    "clustering_model = KMeans(n_clusters=10, init='k-means++', \n",
    "                          n_init=1000, max_iter=1000, tol=0.0001)\n",
    "classes = clustering_model.fit_predict(V)\n",
    "classes = classes.reshape((N_landmarks,2))\n",
    "f_clusters = 20 * classes[:,0] + classes[:,0]\n",
    "l_clusters = np.unique(f_clusters)\n",
    "c_list = []\n",
    "for c in l_clusters:\n",
    "    c_list.append(np.argwhere(f_clusters == c).squeeze())\n",
    "    \n",
    "plt.figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "colors = hsv(np.linspace(0, 1.0, len(c_list)))\n",
    "for i in range(len(c_list)):\n",
    "    indices = c_list[i]\n",
    "    plt.scatter(Face[indices,0], -Face[indices,1], color=colors[i], linewidths=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "newV = V.reshape([N_landmarks,2,num_features]).sum(1)\n",
    "Z = linkage(newV, method='ward')\n",
    "fig = plt.figure(figsize=(30, 15))\n",
    "dn = dendrogram(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Clusters(dict):\n",
    "    def _repr_html_(self):\n",
    "        html = '<table style=\"border: 0;\">'\n",
    "        for c in self:\n",
    "            hx = rgb2hex(colorConverter.to_rgb(c))\n",
    "            html += '<tr style=\"border: 0;\">' \\\n",
    "            '<td style=\"background-color: {0}; ' \\\n",
    "                       'border: 0;\">' \\\n",
    "            '<code style=\"background-color: {0};\">'.format(hx)\n",
    "            html += c + '</code></td>'\n",
    "            html += '<td style=\"border: 0\"><code>' \n",
    "            html += repr(self[c]) + '</code>'\n",
    "            html += '</td></tr>'\n",
    "        \n",
    "        html += '</table>'\n",
    "        \n",
    "        return html\n",
    "    \n",
    "def get_cluster_classes(den, label='ivl'):\n",
    "    cluster_idxs = defaultdict(list)\n",
    "    for c, pi in zip(den['color_list'], den['icoord']):\n",
    "        for leg in pi[1:3]:\n",
    "            i = (leg - 5.0) / 10.0\n",
    "            if abs(i - int(i)) < 1e-5:\n",
    "                cluster_idxs[c].append(int(i))\n",
    "    \n",
    "    cluster_classes = Clusters()\n",
    "    for c, l in cluster_idxs.items():\n",
    "        i_l = [den[label][i] for i in l]\n",
    "        cluster_classes[c] = i_l\n",
    "    \n",
    "    return cluster_classes\n",
    "\n",
    "get_cluster_classes(dn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ad hoc code to generate fixed hierachy, the values are chosen for there to be 4 layers, with the early ones having 5 to 6 clusters and the later stages to have 2 or 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 4\n",
    "threshold = list(np.linspace(0,2,4))\n",
    "threshold  = [0] + list(np.logspace(-0.1,np.log(1.35),n))\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = []\n",
    "for k in threshold:\n",
    "    tree.append(fcluster(Z, k, criterion='distance'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape = tree[0].shape[0]\n",
    "arr = np.concatenate(tree).reshape([shape,len(tree)], order='F') - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = np.repeat(arr, 2, axis=0)\n",
    "\n",
    "for i in range(N_landmarks):\n",
    "    arr[2*i,0] = 2*arr[2*i,0]\n",
    "    arr[2*i+1,0] = 2*arr[2*i+1,0]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(n+1):\n",
    "    print(len(np.unique(arr[:,i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('new_tree', arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
