{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# basic\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "\n",
    "# machine learning\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# custom\n",
    "import video_loader\n",
    "import custom_models as cm\n",
    "import tvgg as tv\n",
    "import tdense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_frames = 12\n",
    "batch_size = 64\n",
    "img_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CK+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes =  {0:'anger', 1:'contempt', 2:'disgust', 3:'fear', 4:'happy', 5:'sadness', 6:'surprise'}\n",
    "N_frames = 12\n",
    "N_classes = len(classes)\n",
    "N_landmarks = 68\n",
    "\n",
    "# preprocessing\n",
    "data_dir = os.path.join('/home','nii','Documents','CK+')\n",
    "\n",
    "data_transforms = transforms.Compose(\n",
    "    [transforms.Resize((64,64))])\n",
    "\n",
    "K = 10\n",
    "k_folders = ['set_' + str(idx) for idx in range(K)]\n",
    "\n",
    "    \n",
    "training_datasets = {x: video_loader.VideoFolder(root=data_dir, image_folder='cohn-kanade-images-crop', \n",
    "                                 label_folder='Emotion', landmark_folder='Landmarks_crop',\n",
    "                                 fold=x, phase='train', classes=classes, n_frames=N_frames, n_landmarks=N_landmarks,\n",
    "                                                 transform=data_transforms,\n",
    "                                 indexing=1)\n",
    "                    for x in k_folders}\n",
    "\n",
    "validation_datasets = {x: video_loader.VideoFolder(root=data_dir, image_folder='cohn-kanade-images-crop', \n",
    "                                 label_folder='Emotion', landmark_folder='Landmarks_crop',\n",
    "                                 fold=x, phase='valid', classes=classes, n_frames=N_frames, n_landmarks=N_landmarks,\n",
    "                                                   transform=data_transforms,\n",
    "                                 indexing=1)\n",
    "                    for x in k_folders}\n",
    "\n",
    "fold = 8\n",
    "\n",
    "training_folds = [x for x in range(K) if x != fold]\n",
    "validation_fold = random.choice(training_folds)\n",
    "training_folds = [x for x in training_folds if x is not validation_fold]\n",
    "\n",
    "cross_datasets = {}\n",
    "cross_datasets['train'] = torch.utils.data.ConcatDataset([training_datasets[k_folders[k]] \n",
    "                                                          for k in training_folds])\n",
    "cross_datasets['val'] = validation_datasets[k_folders[validation_fold]]\n",
    "\n",
    "cross_datasets['test'] = validation_datasets[k_folders[fold]]\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(cross_datasets[x], batch_size=batch_size, shuffle=True,\n",
    "                                              num_workers=4)\n",
    "              for x in ['train', 'val', 'test']}\n",
    "\n",
    "dataset_sizes = {x: len(cross_datasets[x]) for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oulu-CASIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes =  {0:'anger', 1:'disgust', 2:'fear', 3:'happy', 4:'sadness', 5:'surprise'}\n",
    "data_dir = os.path.join('/home','nii','Documents', 'OriginalImg', 'VL')\n",
    "N_frames = 12\n",
    "N_classes = len(classes)\n",
    "N_landmarks = 68\n",
    "\n",
    "data_transforms = transforms.Compose(\n",
    "    [transforms.Resize((64,64))])\n",
    "\n",
    "K = 10\n",
    "k_folders = ['set_' + str(idx) for idx in range(K)]\n",
    "    \n",
    "training_datasets = {x: video_loader.VideoFolder(root=data_dir, image_folder='Strong-crop', \n",
    "                                 label_folder='Strong-emotion', landmark_folder='Landmarks_crop',\n",
    "                                 fold=x, phase='train', classes=classes, img_type='jpeg', n_landmarks=N_landmarks,\n",
    "                                    n_frames=N_frames, transform=data_transforms)\n",
    "                    for x in k_folders}\n",
    "\n",
    "validation_datasets = {x: video_loader.VideoFolder(root=data_dir, image_folder='Strong-crop', \n",
    "                                 label_folder='Strong-emotion', landmark_folder='Landmarks_crop',\n",
    "                                 fold=x, phase='valid', classes=classes, img_type='jpeg', n_landmarks=N_landmarks,\n",
    "                                      n_frames=N_frames, transform=data_transforms)\n",
    "                    for x in k_folders}\n",
    "\n",
    "\n",
    "fold = 1\n",
    "\n",
    "training_folds = [x for x in range(K) if x != fold]\n",
    "validation_fold = random.choice(training_folds)\n",
    "training_folds = [x for x in training_folds if x is not validation_fold]\n",
    "\n",
    "cross_datasets = {}\n",
    "cross_datasets['train'] = torch.utils.data.ConcatDataset([training_datasets[k_folders[k]] \n",
    "                                                          for k in training_folds])\n",
    "cross_datasets['val'] = validation_datasets[k_folders[validation_fold]]\n",
    "\n",
    "cross_datasets['test'] = validation_datasets[k_folders[fold]]\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(cross_datasets[x], batch_size=32,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val', 'test']}\n",
    "\n",
    "dataset_sizes = {x: len(cross_datasets[x]) for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AFEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes =  {0:'neutral', 1:'angry', 2:'disgust', 3:'fear', 4:'happy', 5:'sad', 6:'surprise'}\n",
    "N_frames = 12\n",
    "N_landmarks = 49\n",
    "N_classes = len(classes)\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "# preprocessing\n",
    "data_dir = os.path.join('/home','nii','Documents','EmotiW_2018','Train_AFEW')\n",
    "data_dir_val = os.path.join('/home','nii','Documents','EmotiW_2018','Val_AFEW')\n",
    "\n",
    "data_transforms = transforms.Compose(\n",
    "    [transforms.Resize((64,64))])\n",
    "\n",
    "K = 10\n",
    "k_folders = ['set_' + str(idx) for idx in range(K)]   \n",
    "\n",
    "    \n",
    "training_datasets = {x: video_loader.VideoFolder(root=data_dir, image_folder='cropped_images', \n",
    "                                 label_folder='emotion', landmark_folder='landmarks',\n",
    "                                 fold=x, phase='train', img_type='jpg',\n",
    "                                 classes=classes, n_frames=N_frames, n_landmarks=N_landmarks,\n",
    "                                 transform=data_transforms, indexing=0,\n",
    "                                   are_subjects=False)\n",
    "                    for x in k_folders}\n",
    "\n",
    "\n",
    "validation_datasets = {x: video_loader.VideoFolder(root=data_dir, image_folder='cropped_images', \n",
    "                                 label_folder='emotion', landmark_folder='landmarks',\n",
    "                                 fold=x, phase='valid', img_type='jpg',\n",
    "                                 classes=classes, n_frames=N_frames,  n_landmarks=N_landmarks,\n",
    "                                 transform=data_transforms, indexing=0,\n",
    "                                     are_subjects=False)\n",
    "                    for x in k_folders}\n",
    "\n",
    "testing_datasets = {x: video_loader.VideoFolder(root=data_dir_val, image_folder='cropped_images', \n",
    "                                 label_folder='emotion', landmark_folder='landmarks',\n",
    "                                 fold=x, phase='test', img_type='jpg',\n",
    "                                 classes=classes, n_frames=N_frames,  n_landmarks=N_landmarks,\n",
    "                                 transform=data_transforms, indexing=0,\n",
    "                                     are_subjects=False)\n",
    "                    for x in k_folders}\n",
    "\n",
    "fold = 6\n",
    "\n",
    "training_folds = [x for x in range(K) if x != fold]\n",
    "validation_fold = fold\n",
    "\n",
    "cross_datasets = {}\n",
    "cross_datasets['train'] = torch.utils.data.ConcatDataset([training_datasets[k_folders[k]] \n",
    "                                                          for k in training_folds])\n",
    "cross_datasets['val'] = validation_datasets[k_folders[validation_fold]]\n",
    "\n",
    "cross_datasets['test'] = torch.utils.data.ConcatDataset([testing_datasets[k_folders[k]] \n",
    "                                                          for k in range(K)])\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(cross_datasets[x], batch_size=32, shuffle=True,\n",
    "                                              num_workers=4)\n",
    "              for x in ['train', 'val', 'test']}\n",
    "\n",
    "dataset_sizes = {x: len(cross_datasets[x]) for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source code is here so that the models with the hidden states can be loaded directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BiRNN Model (Many-to-One)\n",
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(BiRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, \n",
    "                            batch_first=True, bidirectional=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Set initial states\n",
    "        if x.is_cuda:\n",
    "            h0 = Variable(torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).cuda()) # 2 for bidirection \n",
    "            \n",
    "        else:\n",
    "            h0 = Variable(torch.zeros(self.num_layers*2, x.size(0), self.hidden_size)) # 2 for bidirection \n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, \n",
    "                            batch_first=True, bidirectional=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Set initial states\n",
    "        if x.is_cuda:\n",
    "            h0 = Variable(torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).cuda()) # 2 for bidirection \n",
    "            c0 = Variable(torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).cuda())\n",
    "            \n",
    "        else:\n",
    "            h0 = Variable(torch.zeros(self.num_layers*2, x.size(0), self.hidden_size)) # 2 for bidirection \n",
    "            c0 = Variable(torch.zeros(self.num_layers*2, x.size(0), self.hidden_size))\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Decode hidden state of last time step\n",
    "        #out = out[:, -1, :]\n",
    "        \n",
    "        return out\n",
    "    \n",
    "\n",
    "def make_layers(cfg):\n",
    "    layers = []\n",
    "    factor = 1\n",
    "    for v in cfg:\n",
    "        # extract layer configuration\n",
    "        mask, hidden_size, n_layers, double, memory = v\n",
    "        if memory:\n",
    "            # memory layer\n",
    "            factor *= 2 # temporary correction --> multiply by the number of previous layers\n",
    "            layers += [BiLSTM(len(mask)*factor, hidden_size, n_layers)]\n",
    "        else:\n",
    "            layers += [nn.ModuleList([BiRNN(len(mask[i])*factor, hidden_size, n_layers)\n",
    "                                for i in range(len(mask))])]\n",
    "            if double:\n",
    "                layers += [nn.ModuleList([BiRNN(hidden_size*2, hidden_size, n_layers)\n",
    "                               for i in range(len(mask))])]\n",
    "        factor = 2 * hidden_size\n",
    "        \n",
    "    return nn.ModuleList(layers)\n",
    "\n",
    "\n",
    "class Flexible(nn.Module):\n",
    "    def __init__(self, cfg, n_landmarks, n_classes, use_mask=True):\n",
    "        super(Flexible, self).__init__()\n",
    "        \n",
    "        self.n_landmarks = n_landmarks\n",
    "        self.n_classes = n_classes\n",
    "        self.cfg = cfg\n",
    "        self.use_mask = use_mask\n",
    "        \n",
    "        # feature extraction\n",
    "        self.features = make_layers(self.cfg)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(480, 8192),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(8192, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(4096, self.n_classes),\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        \"\"\"\n",
    "        if self.use_mask: \n",
    "            x = x.view(batch_size, -1, 2*68)\n",
    "            mask = np.ones((2*68, 1),  dtype=bool)\n",
    "            mask[:34] = False\n",
    "            mask[120:122] = False\n",
    "            mask[128:130] = False\n",
    "            x = x[:,:,np.where(mask)[0]]\n",
    "            \n",
    "        else:\n",
    "            x = x.view(batch_size, -1, 2*49)\n",
    "        \"\"\"\n",
    "\n",
    "        #\"\"\"\n",
    "        x = x.view(batch_size, -1, 2*68)\n",
    "        mask = np.ones((2*68, 1),  dtype=bool)\n",
    "        mask[:34] = False\n",
    "        mask[120:122] = False\n",
    "        mask[128:130] = False\n",
    "        x = x[:,:,np.where(mask)[0]]\n",
    "        #\"\"\"\n",
    "        \n",
    "        num_layer = 0\n",
    "        for v in self.cfg:\n",
    "            # extract layer configuration\n",
    "            \n",
    "            mask, hidden_size, n_layers, double, memory = v\n",
    "            \n",
    "            # LSTM layer\n",
    "            if memory:\n",
    "                x = x.contiguous().view(batch_size, n_layers, -1)\n",
    "                x = self.features[num_layer](x)\n",
    "                x = x.contiguous().view(batch_size, -1)\n",
    "                num_layer += 1\n",
    "              \n",
    "            # RNN layer\n",
    "            else:\n",
    "                out_features = []\n",
    "                for i in range(len(mask)):\n",
    "                    if double:\n",
    "                        landmarks = x[:,:,mask[i]].view(batch_size, n_layers, -1)\n",
    "                        landmarks = self.features[num_layer+1][i](self.features[num_layer][i](landmarks))\n",
    "\n",
    "                    else:\n",
    "                        landmarks = x[:,:,mask[i]].view(batch_size, n_layers, -1)\n",
    "                        landmarks = self.features[num_layer][i](landmarks)\n",
    "\n",
    "                    out_features.append(landmarks)\n",
    "                    \n",
    "                if double:\n",
    "                    num_layer += 2\n",
    "                else:\n",
    "                    num_layer += 1\n",
    "\n",
    "                x = torch.stack(out_features).permute(1,2,0,3)\n",
    "                \n",
    "        # classification\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del bilstm\n",
    "del tvgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_folder = 'model'\n",
    "#bilstm = Flexible(my_config, N_landmarks, N_classes)\n",
    "#load_valid(bilstm, os.path.join(save_folder, 'custom_1.pt'))\n",
    "#bilstm.load_state_dict(torch.load(os.path.join(save_folder, 'custom_1.pt')), strict=False)\n",
    "bilstm = torch.load(os.path.join(save_folder, 'manual_oulu1.pt'))\n",
    "\n",
    "#tvgg = tdense.densenet121(num_classes=7)\n",
    "tvgg = tv.vgg11_bn(num_classes=N_classes, n_frames=N_frames)\n",
    "#tvgg.load_state_dict(torch.load(os.path.join(save_folder, 'dense_finetune8.pt')))\n",
    "#tvgg.load_state_dict(torch.load(os.path.join(save_folder, 'vgg_finetune8.pt')))\n",
    "tvgg.load_state_dict(torch.load(os.path.join(save_folder, 'vgg_finetune_oulu1.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tvgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze feature extractors and only tune classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    bilstm = bilstm.cuda()\n",
    "    tvgg = tvgg.cuda()\n",
    "\n",
    "for param in bilstm.features.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in bilstm.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "for param in tvgg.features.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in tvgg.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "parameters = filter(lambda p: p.requires_grad, itertools.chain(bilstm.parameters(), tvgg.parameters()))\n",
    "\n",
    "optimizer = optim.Adam(parameters, lr=0.001, weight_decay=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since bilstm underperforms, better results are obtained when more weight is given to the TCNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tuning parameters\n",
    "lambda_1 = 1\n",
    "lambda_2 = 1\n",
    "lambda_3 = 0.1\n",
    "\n",
    "def train_model(tvgg, bilstm, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_tvgg_wts = copy.deepcopy(tvgg.state_dict())\n",
    "    best_bilstm_wts = copy.deepcopy(bilstm.state_dict())\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                tvgg.train(True)  # Set model to training mode\n",
    "                bilstm.train(True)  # Set model to training mode\n",
    "\n",
    "            else:\n",
    "                tvgg.train(False)  # Set model to evaluate mode\n",
    "                bilstm.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                # get the inputs\n",
    "                inputs, labels, landmarks = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                    landmarks = Variable(landmarks.float().cuda())\n",
    "                else:\n",
    "                    inputs, labels, landmarks = Variable(inputs), Variable(labels), Variable(landmarks.float())\n",
    "                    \n",
    "                # subsample landmarks for blstm\n",
    "                b_s = landmarks.size(0)\n",
    "                landmarks = landmarks.view(b_s, N_frames, 2*N_landmarks)\n",
    "                slices = int(landmarks.size(1)*0.25) \n",
    "                idx = np.linspace(0, landmarks.size(1)-1, slices, dtype=np.int)\n",
    "                landmarks = landmarks[:,idx,:]\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                if b_s != 1:\n",
    "                    outputs_tvgg = tvgg(torch.squeeze(inputs))\n",
    "                else:\n",
    "                    outputs_tvgg = tvgg(torch.squeeze(inputs).unsqueeze(0))\n",
    "                    \n",
    "                outputs_bilstm = bilstm(landmarks)\n",
    "                \n",
    "                outputs = outputs_tvgg + outputs_bilstm\n",
    "                \n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                \n",
    "                loss_1 = criterion(outputs_tvgg, labels)\n",
    "                loss_2 = criterion(outputs_bilstm, labels)\n",
    "                loss_3 = criterion(outputs, labels)\n",
    "                \n",
    "                loss = lambda_1 * loss_1 + lambda_2 * loss_2 + lambda_3 * loss_3\n",
    "                \n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0] * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "                \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc >= best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_tvgg_wts = copy.deepcopy(tvgg.state_dict())\n",
    "                best_bilstm_wts = copy.deepcopy(bilstm.state_dict())\n",
    "\n",
    "        print()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    tvgg.load_state_dict(best_tvgg_wts)\n",
    "    bilstm.load_state_dict(best_bilstm_wts)\n",
    "    return tvgg, bilstm, best_acc\n",
    "\n",
    "\n",
    "def test_model(tvgg, bilstm, criterion):\n",
    "    \n",
    "    tvgg.train(False)\n",
    "    bilstm.train(False)\n",
    "    \n",
    "    truth = []\n",
    "    prediction = []\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "\n",
    "    # Iterate over data.\n",
    "    for data in dataloaders['test']:\n",
    "        # get the inputs\n",
    "        inputs, labels, landmarks = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        if use_gpu:\n",
    "            inputs = Variable(inputs.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            landmarks = Variable(landmarks.float().cuda())\n",
    "        else:\n",
    "            inputs, labels, landmarks = Variable(inputs), Variable(labels), Variable(landmarks.float())\n",
    "         \n",
    "        # subsample landmarks for blstm\n",
    "        b_s = landmarks.size(0)\n",
    "        landmarks = landmarks.view(b_s, N_frames, 2*N_landmarks)\n",
    "        slices = int(landmarks.size(1)*0.25) \n",
    "        idx = np.linspace(0, landmarks.size(1)-1, slices, dtype=np.int)\n",
    "        landmarks = landmarks[:,idx,:]\n",
    "        \n",
    "        # forward\n",
    "        if b_s != 1:\n",
    "            outputs_tvgg = tvgg(torch.squeeze(inputs))\n",
    "        else:\n",
    "            outputs_tvgg = tvgg(torch.squeeze(inputs).unsqueeze(0))\n",
    "        outputs_bilstm = bilstm(landmarks)\n",
    "        outputs = outputs_tvgg + outputs_bilstm\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        \n",
    "        truth.extend(labels.cpu().data.numpy().tolist())\n",
    "        prediction.extend(preds.cpu().numpy().tolist())\n",
    "\n",
    "        loss_1 = criterion(outputs_tvgg, labels)\n",
    "        loss_2 = criterion(outputs_bilstm, labels)\n",
    "        loss_3 = criterion(outputs, labels)\n",
    "\n",
    "        loss = lambda_1 * loss_1 + lambda_2 * loss_2 + lambda_3 * loss_3\n",
    "        \n",
    "        # statistics\n",
    "        running_loss += loss.data[0] * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    total_loss = running_loss / dataset_sizes['test']\n",
    "    total_acc = running_corrects / dataset_sizes['test']\n",
    "\n",
    "    print('{} Loss: {:.4f} Acc: {:.4f}'.format('test', total_loss, total_acc))\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(truth, prediction, labels=list(range(N_classes)))\n",
    "\n",
    "    return total_loss, total_acc, cnf_matrix\n",
    "\n",
    "\n",
    "def test_single_model(model, criterion):\n",
    "    \n",
    "    model.train(False)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "\n",
    "    # Iterate over data.\n",
    "    for data in dataloaders['test']:\n",
    "        \n",
    "        # get the inputs\n",
    "        inputs, labels, _ = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        if use_gpu:\n",
    "            inputs = Variable(inputs.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        b_s = inputs.size(0)\n",
    "        \n",
    "        # forward\n",
    "        if b_s != 1:\n",
    "            outputs = model(torch.squeeze(inputs))\n",
    "        else:\n",
    "            outputs = model(torch.squeeze(inputs).unsqueeze(0))\n",
    "        \n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # statistics\n",
    "        running_loss += loss.data[0] * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    total_loss = running_loss / dataset_sizes['test']\n",
    "    total_acc = running_corrects / dataset_sizes['test']\n",
    "\n",
    "    print('{} Loss: {:.4f} Acc: {:.4f}'.format('test', total_loss, total_acc))\n",
    "\n",
    "    return total_loss, total_acc\n",
    "\n",
    "\n",
    "def test_landmark_model(model, criterion):\n",
    "    \n",
    "    model.train(False)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    \n",
    "    truth = []\n",
    "    prediction = []\n",
    "\n",
    "    # Iterate over data.\n",
    "    for data in dataloaders['test']:\n",
    "        # get the inputs\n",
    "        _, labels, landmarks = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        if use_gpu:\n",
    "            inputs = Variable(landmarks.float().cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(landmarks.float()), Variable(labels)\n",
    "\n",
    "        # subsample landmarks for blstm\n",
    "        b_s = inputs.size(0)\n",
    "        inputs = inputs.view(b_s, N_frames, 2*N_landmarks)\n",
    "        slices = int(inputs.size(1)*0.25) \n",
    "        idx = np.linspace(0, inputs.size(1)-1, slices, dtype=np.int)\n",
    "        inputs = inputs[:,idx,:]\n",
    "        \n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        \n",
    "        truth.extend(labels.cpu().data.numpy().tolist())\n",
    "        prediction.extend(preds.cpu().numpy().tolist())\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # statistics\n",
    "        running_loss += loss.data[0] * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    total_loss = running_loss / dataset_sizes['test']\n",
    "    total_acc = running_corrects / dataset_sizes['test']\n",
    "\n",
    "    print('{} Loss: {:.4f} Acc: {:.4f}'.format('test', total_loss, total_acc))\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(truth, prediction, labels=list(range(N_classes)))\n",
    "\n",
    "    return total_loss, total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tvgg, bilstm, accuracy = train_model(tvgg, bilstm, criterion, optimizer, num_epochs=10)\n",
    "test_loss, test_accuracy, conf = test_model(tvgg, bilstm, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_accuracy = []\n",
    "\n",
    "for fold in range(K):\n",
    "    print('Starting fold ' + str(fold) + ' ...')\n",
    "    \n",
    "    # reassign datasets to training, validation and testing\n",
    "    training_folds = [x for x in range(K) if x != fold]\n",
    "    validation_fold = random.choice(training_folds)\n",
    "    training_folds = [x for x in training_folds if x is not validation_fold]\n",
    "    \n",
    "    cross_datasets = {}\n",
    "    cross_datasets['train'] = torch.utils.data.ConcatDataset([training_datasets[k_folders[k]] \n",
    "                                                              for k in training_folds])\n",
    "    cross_datasets['val'] = validation_datasets[k_folders[validation_fold]]\n",
    "    \n",
    "    cross_datasets['test'] = validation_datasets[k_folders[fold]]\n",
    "\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(cross_datasets[x], batch_size=64,\n",
    "                                                 shuffle=True, num_workers=4)\n",
    "                  for x in ['train', 'val', 'test']}\n",
    "    dataset_sizes = {x: len(cross_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "        \n",
    "    #tvgg = tdense.densenet121(num_classes=7)\n",
    "    #tvgg.load_state_dict(torch.load(os.path.join(save_folder, 'dense_finetune' + str(fold) + '.pt')))\n",
    "    \n",
    "    model = tv.vgg11_bn(num_classes=N_classes, n_frames=N_frames)\n",
    "    model.load_state_dict(torch.load(os.path.join(save_folder, 'vgg_finetune_oulu' + str(fold) + '.pt')))\n",
    "    model.eval()\n",
    "    \n",
    "    if use_gpu:\n",
    "        model = model.cuda()\n",
    "    \n",
    "    test_loss, test_accuracy = test_single_model(model, criterion)\n",
    "    k_accuracy.append(test_accuracy)\n",
    "    \n",
    "    del model\n",
    "    \n",
    "print('Mean value of test accuracy over ' + str(K) + '-fold crossvalidation is: ' \n",
    "      + str(sum(k_accuracy) / float(len(k_accuracy))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_accuracy = []\n",
    "save_folder = 'model'\n",
    "\n",
    "for fold in range(K):\n",
    "    print('Starting fold ' + str(fold) + ' ...')\n",
    "    \n",
    "    # reassign datasets to training, validation and testing\n",
    "    training_folds = [x for x in range(K) if x != fold]\n",
    "    validation_fold = random.choice(training_folds)\n",
    "    training_folds = [x for x in training_folds if x is not validation_fold]\n",
    "    \n",
    "    cross_datasets = {}\n",
    "    cross_datasets['train'] = torch.utils.data.ConcatDataset([training_datasets[k_folders[k]] \n",
    "                                                              for k in training_folds])\n",
    "    cross_datasets['val'] = validation_datasets[k_folders[validation_fold]]\n",
    "    \n",
    "    cross_datasets['test'] = validation_datasets[k_folders[fold]]\n",
    "\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(cross_datasets[x], batch_size=64,\n",
    "                                                 shuffle=True, num_workers=4)\n",
    "                  for x in ['train', 'val', 'test']}\n",
    "    dataset_sizes = {x: len(cross_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "        \n",
    "    bilstm = torch.load(os.path.join(save_folder, 'manual_oulu' + str(fold) + '.pt'))\n",
    "    bilstm.eval()\n",
    "    \n",
    "    if use_gpu:\n",
    "        bilstm = bilstm.cuda()\n",
    "    \n",
    "    test_loss, test_accuracy = test_landmark_model(bilstm, criterion)\n",
    "    k_accuracy.append(test_accuracy)\n",
    "    \n",
    "    del bilstm\n",
    "    \n",
    "print('Mean value of test accuracy over ' + str(K) + '-fold crossvalidation is: ' \n",
    "      + str(sum(k_accuracy) / float(len(k_accuracy))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_accuracy = []\n",
    "save_folder = 'model'\n",
    "conf_math = np.zeros((N_classes, N_classes))\n",
    "\n",
    "for fold in range(K):\n",
    "    \n",
    "    print('Starting fold ' + str(fold) + ' ...')\n",
    "    \n",
    "    # reassign datasets to training, validation and testing\n",
    "    training_folds = [x for x in range(K) if x != fold]\n",
    "    validation_fold = random.choice(training_folds)\n",
    "    training_folds = [x for x in training_folds if x is not validation_fold]\n",
    "    \n",
    "    cross_datasets = {}\n",
    "    cross_datasets['train'] = torch.utils.data.ConcatDataset([training_datasets[k_folders[k]] \n",
    "                                                              for k in training_folds])\n",
    "    cross_datasets['val'] = validation_datasets[k_folders[validation_fold]]\n",
    "    \n",
    "    cross_datasets['test'] = validation_datasets[k_folders[fold]]\n",
    "\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(cross_datasets[x], batch_size=batch_size,\n",
    "                                                 shuffle=True, num_workers=4)\n",
    "                  for x in ['train', 'val', 'test']}\n",
    "    dataset_sizes = {x: len(cross_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "    \n",
    "    # init model\n",
    "    #bilstm = Flexible(my_config, N_landmarks, N_classes)\n",
    "    #bilstm.load_state_dict(torch.load(os.path.join(save_folder, 'phrnn.pt')))\n",
    "    #bilstm = torch.load(os.path.join(save_folder, 'custom_' + str(fold) + '.pt'))\n",
    "    bilstm = torch.load(os.path.join(save_folder, 'manual_oulu' + str(fold) + '.pt'))\n",
    "    \n",
    "    \n",
    "    #tvgg = tdense.densenet121(num_classes=7)\n",
    "    #tvgg.load_state_dict(torch.load(os.path.join(save_folder, 'dense_finetune' + str(fold) + '.pt')))\n",
    "    \n",
    "    tvgg = tv.vgg11_bn(num_classes=N_classes, n_frames=N_frames)\n",
    "    #tvgg.load_state_dict(torch.load(os.path.join(save_folder, 'vgg_finetune_ck' + str(fold) + '.pt')))\n",
    "    tvgg.load_state_dict(torch.load(os.path.join(save_folder, 'vgg_finetune_oulu' + str(fold) + '.pt')))\n",
    "\n",
    "    if use_gpu:\n",
    "        bilstm = bilstm.cuda()\n",
    "        tvgg = tvgg.cuda()\n",
    "\n",
    "    for param in bilstm.features.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for param in bilstm.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    for param in tvgg.features.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for param in tvgg.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    parameters = filter(lambda p: p.requires_grad, itertools.chain(bilstm.parameters(), tvgg.parameters()))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.Adam(parameters, lr=0.001, weight_decay=5e-3)\n",
    "\n",
    "    # train model\n",
    "    tvgg, bilstm, val_accuracy = train_model(tvgg, bilstm, criterion, optimizer, num_epochs=3)\n",
    "    test_loss, test_accuracy, conf = test_model(tvgg, bilstm, criterion)\n",
    "    conf_math += conf\n",
    "    \n",
    "    print('Finished fold ' + str(fold) + ' with validation accuracy of ' + str(val_accuracy))\n",
    "    k_accuracy.append(test_accuracy)\n",
    "    del bilstm\n",
    "    del tvgg\n",
    "\n",
    "print('Mean value of test accuracy over ' + str(K) + '-fold crossvalidation is: ' \n",
    "      + str(sum(k_accuracy) / float(len(k_accuracy))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(k_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del bilstm\n",
    "del tvgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    #plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(conf_math, classes=list(classes.values()), normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
